{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dead0dc0",
   "metadata": {},
   "source": [
    "# Clustering de séries temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e19233",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:/Users/gabri/OneDrive/Bureau/Cours ENSAE/2ème année/Stage/Données/forecasting.parquet.gzip\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1a69d",
   "metadata": {},
   "source": [
    "On mets les dates au format temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04281825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_index']=pd.to_datetime(df['time_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb6612",
   "metadata": {},
   "source": [
    "On regroupe ensuite les séries temporelles selon l'indice du produit. On effectue une copie puisqu'on va d'abord regarder les résultats d'un clustering avec une distance euclidienne donc on complétera les séries par des zéros et on utilisera ensuite la DTW qui ne nécéssite pas de séries de même taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_produit=df['product_index'].unique()\n",
    "myseries=[df[['time_index','ordered_volumes']][df['product_index']==k] for k in indice_produit]\n",
    "for k in range(len(myseries)):\n",
    "    myseries[k].set_index('time_index',inplace=True)\n",
    "    myseries[k].sort_index(inplace=True)\n",
    "myseries2=myseries.copy()\n",
    "indice_temps=[series.index for series in myseries2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5bdf0",
   "metadata": {},
   "source": [
    "On complète donc les séries pour qu'elle ait la même taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_length=[len(series) for series in myseries]\n",
    "max_len = max(series_length)\n",
    "longest_series = None\n",
    "for series in myseries:\n",
    "    if len(series) == max_len:\n",
    "        longest_series = series\n",
    "for i in range(len(myseries)):\n",
    "    if len(myseries[i])!= max_len:\n",
    "        myseries[i] = myseries[i].reindex(longest_series.index,fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d3d59",
   "metadata": {},
   "source": [
    "On normalise les séries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1377206",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(myseries)):\n",
    "    scaler = MinMaxScaler()\n",
    "    myseries[i] = MinMaxScaler().fit_transform(myseries[i])\n",
    "    myseries[i]= myseries[i].reshape(len(myseries[i]))\n",
    "    myseries2[i] = MinMaxScaler().fit_transform(myseries2[i])\n",
    "    myseries2[i]= myseries2[i].reshape(len(myseries2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4596ea",
   "metadata": {},
   "source": [
    "## Clustering Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da9a22",
   "metadata": {},
   "source": [
    "### Kmeans avec les séries originales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a14ee",
   "metadata": {},
   "source": [
    "On traçe l'inertie pour savoir le nombre de clusters à choisir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95103c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertie=np.empty(25,dtype='float')\n",
    "\n",
    "for i in range(1,26):\n",
    "    kmeans = KMeans(n_clusters=i,max_iter=5000)\n",
    "    inertie[i-1] = kmeans.fit(myseries).inertia_\n",
    "plt.plot(range(1,26),inertie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e542b2",
   "metadata": {},
   "source": [
    "Avec la règle du coude, on voit qu'il faudrait choisir entre 3 et 6 clusters.\n",
    "Pour ici on va prendre 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfe9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,max_iter=5000)\n",
    "\n",
    "labels_kmeans = kmeans.fit_predict(myseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94ecb8",
   "metadata": {},
   "source": [
    "On représente les séries d'un cluster en gris sur un même graphe avec tracé en rouge le centroïde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4,figsize=(25,10))\n",
    "fig.suptitle('Clusters')\n",
    "column_j=0\n",
    "for label in set(labels_kmeans):\n",
    "    cluster = []\n",
    "    for i in range(len(labels_kmeans)):\n",
    "            if(labels_kmeans[i]==label):\n",
    "                axs[column_j].plot(longest_series.index,myseries[i],c=\"gray\",alpha=0.4)\n",
    "                cluster.append(myseries[i])\n",
    "    if len(cluster) > 0:\n",
    "        axs[ column_j].plot(longest_series.index,np.average(np.vstack(cluster),axis=0),c=\"red\")\n",
    "    axs[ column_j].set_title(\"Cluster \"+str(column_j))\n",
    "    column_j+=1     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583f198",
   "metadata": {},
   "source": [
    "On peut regarder les indices de chacun des clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_names_for_labels_kmeans = [f\"Cluster {label}\" for label in labels_kmeans]\n",
    "prédiction_kmeans=pd.DataFrame(zip(indice_produit,fancy_names_for_labels_kmeans),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")\n",
    "for k in range(4):\n",
    "    print(prédiction_kmeans[prédiction_kmeans['Cluster']==f'Cluster {k}'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd8a92",
   "metadata": {},
   "source": [
    "### Kmeans avec une ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae98fc",
   "metadata": {},
   "source": [
    "On va effectuer une analyse en composante principale pour voir si les résultats sont similaires\n",
    "On regarde l'histogramme de la variance expliquée par la n-ième composante pour choisir le nombre de composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ad7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "pca.fit(myseries)\n",
    "plt.hist(range(1,21),weights=pca.explained_variance_ratio_,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f58df0",
   "metadata": {},
   "source": [
    "On choisit 3 composantes (règle du coude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5a236",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "myseries_transformed = pca.fit_transform(myseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480d05",
   "metadata": {},
   "source": [
    "On trace de nouveau l'inertie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertie=np.empty(25,dtype='float')\n",
    "\n",
    "for i in range(1,26):\n",
    "    kmeans = KMeans(n_clusters=i,max_iter=5000)\n",
    "    inertie[i-1] = kmeans.fit(myseries_transformed).inertia_\n",
    "plt.plot(range(1,26),inertie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cf50c",
   "metadata": {},
   "source": [
    "On a le même type de courbe, on va donc choisir à nouveau 4 clusters et observer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbbb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pca = KMeans(n_clusters=4,max_iter=5000)\n",
    "\n",
    "labels_pca = kmeans_pca.fit_predict(myseries_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a330b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4,figsize=(25,10))\n",
    "fig.suptitle('Clusters')\n",
    "column_j=0\n",
    "for label in set(labels_pca):\n",
    "    cluster = []\n",
    "    for i in range(len(labels_pca)):\n",
    "            if(labels_pca[i]==label):\n",
    "                axs[column_j].plot(longest_series.index,myseries[i],c=\"gray\",alpha=0.4)\n",
    "                cluster.append(myseries[i])\n",
    "    if len(cluster) > 0:\n",
    "        axs[ column_j].plot(longest_series.index,np.average(np.vstack(cluster),axis=0),c=\"red\")\n",
    "    axs[column_j].set_title(\"Cluster \"+str(column_j))\n",
    "    column_j+=1\n",
    " \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dae33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_names_for_labels_pca = [f\"Cluster {label}\" for label in labels_pca]\n",
    "prédiction_pca=pd.DataFrame(zip(indice_produit,fancy_names_for_labels_pca),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")\n",
    "for k in range(4):\n",
    "    print(prédiction_pca[prédiction_pca['Cluster']==f'Cluster {k}'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e72fa",
   "metadata": {},
   "source": [
    "## Clustering DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea959428",
   "metadata": {},
   "source": [
    "On passe la série au format Time Series pour tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=to_time_series_dataset(myseries2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df37c59",
   "metadata": {},
   "source": [
    "### Kmeans "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d88f03",
   "metadata": {},
   "source": [
    "On peut traçer l'inertie mais ceci prend un peu plus de temps (je laisse quand même le code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1e3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inertie=np.empty((1,10),dtype='float')\n",
    "\n",
    "#for j in range(1):\n",
    "#    for i in range(1,11):\n",
    "#        km = TimeSeriesKMeans(n_clusters=i, metric=\"dtw\")\n",
    "#        inertie[j,i-1] = km.fit(X).inertia_\n",
    "#    print(j)\n",
    "#plt.plot(range(1,11),np.mean(inertie,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fd599",
   "metadata": {},
   "source": [
    "La courbe est assez similaire mais on va s'intéresser par la suite à 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_km = TimeSeriesKMeans(n_clusters=3, metric=\"dtw\")\n",
    "\n",
    "labels_dtw = dtw_km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_names_for_labels_dtw = [f\"Cluster {label}\" for label in labels_dtw]\n",
    "prediction_dtw=pd.DataFrame(zip(indice_produit,fancy_names_for_labels_dtw),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7567a4",
   "metadata": {},
   "source": [
    "On regarde les séries de chaque cluster (il faut redimensionner la deuxième coordonnée de figsize en fonction des résultats pour avoir des cases qui ne sont pas trop écrasées ou allongées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb204640",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dtw[prediction_dtw['Cluster']==f'Cluster {0}'].index)//4+1,4,figsize=(25,15))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dtw[prediction_dtw['Cluster']==f'Cluster {0}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e29588",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dtw[prediction_dtw['Cluster']==f'Cluster {1}'].index)//4+1,4,figsize=(25,25))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dtw[prediction_dtw['Cluster']==f'Cluster {1}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c22eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dtw[prediction_dtw['Cluster']==f'Cluster {2}'].index)//4+1,4,figsize=(25,10))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dtw[prediction_dtw['Cluster']==f'Cluster {2}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf71df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    print(prediction_dtw[prediction_dtw['Cluster']==f'Cluster {k}'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4fa88",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40599c90",
   "metadata": {},
   "source": [
    "On utilise maintenant l'algorithme de hierarchical clustering et on trace les dendrogrammes pour chaque type de lien. Comme il n'existe pas de fonction pour faire cet algorithme avec la DTW, on va calculer les distances avant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f02fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_precomputed=np.zeros((125,125))\n",
    "for i in range(125):\n",
    "    for j in range(125):\n",
    "        dtw_precomputed[i,j]=dtw(myseries2[i], myseries2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hac_average=AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='average',compute_distances=True)\n",
    "hac_single=AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='single',compute_distances=True)\n",
    "hac_complete=AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='complete',compute_distances=True)\n",
    "modele_average = hac_average.fit(dtw_precomputed)\n",
    "modele_single = hac_single.fit(dtw_precomputed)\n",
    "modele_complete = hac_complete.fit(dtw_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acdad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  \n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(modele_average, truncate_mode=\"level\", p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(modele_single, truncate_mode=\"level\", p=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501520a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(modele_complete, truncate_mode=\"level\", p=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335d304",
   "metadata": {},
   "source": [
    "Au vu des dendrogrammes, on va utilise le linkage complete. On va faire de nouveau 3 clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f809af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hac=AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='complete')\n",
    "\n",
    "labels_hac = hac.fit_predict(dtw_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61fbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_names_for_labels_hac = [f\"Cluster {label}\" for label in labels_hac]\n",
    "prediction_hac=pd.DataFrame(zip(indice_produit,fancy_names_for_labels_hac),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eae919",
   "metadata": {},
   "source": [
    "On observe les séries pour chaque cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(len(prediction_hac[prediction_hac['Cluster']==f'Cluster {0}'].index)//4+1,4,figsize=(25,35))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_hac[prediction_hac['Cluster']==f'Cluster {0}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b56fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(len(prediction_hac[prediction_hac['Cluster']==f'Cluster {0}'].index)//4+1,4,figsize=(25,35))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_hac[prediction_hac['Cluster']==f'Cluster {1}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig, axs = plt.subplots(len(prediction_hac[prediction_hac['Cluster']==f'Cluster {0}'].index)//4+1,4,figsize=(25,35))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_hac[prediction_hac['Cluster']==f'Cluster {2}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    print(prediction_hac[prediction_hac['Cluster']==f'Cluster {k}'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380a6e0",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f759f8",
   "metadata": {},
   "source": [
    "On estime d'abord les paramètres de l'algorithme. La distance e est choisie pour qu'une grande partie des points ait la distance minimale inférieure à ce point. Le nombre n est choisi de telle sorte que le nombre de voisin à une distance inférieure à n pour un nombre suffisamment grand de point. Ici, on essaye les quantiles à 95 % et à 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea45902",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.copy(dtw_precomputed)\n",
    "e=np.quantile(np.sort(a,axis=0)[1],0.95)\n",
    "n=np.quantile(np.count_nonzero(a<=e,axis=0),0.05)\n",
    "e2=np.quantile(np.sort(a,axis=0)[1],0.9)\n",
    "n2=np.quantile(np.count_nonzero(a<=e2,axis=0),0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a5c36",
   "metadata": {},
   "source": [
    "On regarde ici les résultats pour 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b98920",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan=DBSCAN(eps=e,min_samples=n,metric='precomputed')\n",
    "labels_dbscan = dbscan.fit_predict(dtw_precomputed)\n",
    "fancy_names_for_labels_dbscan= [f\"Cluster {label}\" for label in labels_dbscan]\n",
    "prediction_dbscan=pd.DataFrame(zip(indice_produit,fancy_names_for_labels_dbscan),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21c9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(-1,2):\n",
    "    print(prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {k}'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede30415",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {-1}'].index)//4+1,4,figsize=(25,50))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {-1}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636133db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {0}'].index)//4+1,4,figsize=(25,50))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {0}'].index:\n",
    "    axs[row_i,column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {1}'].index)//4+1,4,figsize=(25,5))\n",
    "row_i=0\n",
    "column_j=0\n",
    "for i in prediction_dbscan[prediction_dbscan['Cluster']==f'Cluster {1}'].index:\n",
    "    axs[column_j].plot(indice_temps[np.where(indice_produit==i)[0][0]],myseries2[np.where(indice_produit==i)[0][0]],c=\"blue\")\n",
    "    column_j+=1\n",
    "    if column_j%4==0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c287a",
   "metadata": {},
   "source": [
    "## Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea455fb1",
   "metadata": {},
   "source": [
    "### Comparaison inertie entre les algorithmes Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdf4a4",
   "metadata": {},
   "source": [
    "On regarde l'inertie pour les différents modèles utilisant l'algorithme des kmeans. On rappelle qu'on préfère une petite inertie pour un petit nombre de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_inertie=np.array([[KMeans(n_clusters=3,max_iter=5000).fit(myseries_transformed).inertia_,KMeans(n_clusters=4,max_iter=5000).fit(myseries_transformed3).inertia_,KMeans(n_clusters=5,max_iter=5000).fit(myseries_transformed).inertia_,KMeans(n_clusters=6,max_iter=5000).fit(myseries_transformed).inertia_],\n",
    "                     [KMeans(n_clusters=3,max_iter=5000).fit(myseries).inertia_,KMeans(n_clusters=4,max_iter=5000).fit(myseries).inertia_,KMeans(n_clusters=5,max_iter=5000).fit(myseries).inertia_,KMeans(n_clusters=6,max_iter=5000).fit(myseries).inertia_],\n",
    "                      [TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit(X).inertia_,TimeSeriesKMeans(n_clusters=4, metric=\"dtw\").fit(X).inertia_,TimeSeriesKMeans(n_clusters=5, metric=\"dtw\").fit(X).inertia_,TimeSeriesKMeans(n_clusters=6, metric=\"dtw\").fit(X).inertia_]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "column_labels=[\"n=3\", \"n=4\", \"n=5\",\"n=6\"]\n",
    "row_labels=[\"PCA 3 Composantes\",\"Kmeans\",\"DTW\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=modeles_inertie,colLabels=column_labels,rowLabels=row_labels,loc=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b480e",
   "metadata": {},
   "source": [
    "On voit que l'algorithme avec la DTW est largement meilleure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3193ed3",
   "metadata": {},
   "source": [
    "### Comparaison algorithmes utilisant la DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e38629",
   "metadata": {},
   "source": [
    "#### Silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad77095",
   "metadata": {},
   "source": [
    "On regarde le silhouette score qui est optimal quand il est proche de 1. On ne regarde que les algorithmes utilisant la DTW, on regarde le Kmeans, hierarchical clustering avec average et complete linkage et DBSCAN avec les deux paires de paramètres calculées avant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e14b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_silhouette=np.zeros((5,4))\n",
    "a=silhouette_score2(X,DBSCAN(eps=e,min_samples=n,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "b=silhouette_score2(X,DBSCAN(eps=e2,min_samples=n2,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "c=np.array([silhouette_score2(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed))])\n",
    "d= np.array([silhouette_score2(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),silhouette_score2(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed))])\n",
    "modeles_silhouette[0]=np.array([silhouette_score2(X,TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X)),silhouette_score2(X,TimeSeriesKMeans(n_clusters=4, metric=\"dtw\").fit_predict(X)),silhouette_score2(X,TimeSeriesKMeans(n_clusters=5, metric=\"dtw\").fit_predict(X)),silhouette_score2(X,TimeSeriesKMeans(n_clusters=6, metric=\"dtw\").fit_predict(X))])\n",
    "modeles_silhouette[1]=c\n",
    "modeles_silhouette[2]=d                                \n",
    "modeles_silhouette[3]=np.full(4,a)\n",
    "modeles_silhouette[4]=np.full(4,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "column_labels=[\"n=3\", \"n=4\", \"n=5\",\"n=6\"]\n",
    "row_labels=[\"DTW\",\"HAC Complete\",\"HAC average\",\"DBSCAN eps=1,82 min_samples=2\",\"DBSCAN eps=1,72 min_samples=2\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=modeles_silhouette,colLabels=column_labels,rowLabels=row_labels,loc=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e76ab",
   "metadata": {},
   "source": [
    "#### Score de Calinski-Harabasz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b20dd",
   "metadata": {},
   "source": [
    "On regarde le score de Calinski-Harabasz qui va de 0 à l'infini où l'infini est la meilleure classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dfcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGSS(X,labels):\n",
    "    bgss=0\n",
    "    C=dtw_barycenter_averaging(X)\n",
    "    for k in np.unique(labels):\n",
    "        n_k=len(np.where(labels==k)[0])\n",
    "        C_k=dtw_barycenter_averaging(X[np.where(labels==k)])\n",
    "        bgss+=n_k*dtw(C_k,C)**2\n",
    "    return bgss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGSS(X,labels):\n",
    "    WGSS=0\n",
    "    for k in np.unique(labels):\n",
    "        WGSSk=0\n",
    "        C_k=dtw_barycenter_averaging(X[np.where(labels==k)])\n",
    "        for x in np.where(labels==k)[0]:\n",
    "            WGSSk+=dtw(C_k,X[x])**2\n",
    "        WGSS+=WGSSk\n",
    "    return WGSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee873e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calinski_Harabasz_score(X,labels):\n",
    "    N=len(X)\n",
    "    K=len(np.unique(labels))\n",
    "    return BGSS(X,labels)*(N-K)/(WGSS(X,labels)*(K-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f08256",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_calinski_harabasz=np.zeros((1,5,4))\n",
    "a=Calinski_Harabasz_score(X,DBSCAN(eps=e,min_samples=n,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "b=Calinski_Harabasz_score(X,DBSCAN(eps=e2,min_samples=n2,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "c=np.array([Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed))])\n",
    "d=np.array([Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Calinski_Harabasz_score(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed))])\n",
    "for k in range(1):\n",
    "    modeles_calinski_harabasz[k,0]=np.array([Calinski_Harabasz_score(X,TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X)),Calinski_Harabasz_score(X,TimeSeriesKMeans(n_clusters=4, metric=\"dtw\").fit_predict(X)),Calinski_Harabasz_score(X,TimeSeriesKMeans(n_clusters=5, metric=\"dtw\").fit_predict(X)),Calinski_Harabasz_score(X,TimeSeriesKMeans(n_clusters=6, metric=\"dtw\").fit_predict(X))])\n",
    "    modeles_calinski_harabasz[k,1]=c\n",
    "    modeles_calinski_harabasz[k,2]=d                                  \n",
    "    modeles_calinski_harabasz[k,3]=np.full(4,a)\n",
    "    modeles_calinski_harabasz[k,4]=np.full(4,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1,figsize=(10,10))\n",
    "column_labels=[\"n=3\", \"n=4\", \"n=5\",\"n=6\"]\n",
    "row_labels=[\"DTW\",\"HAC Complete\",\"HAC average\",\"DBSCAN eps=1,82 min_samples=2\",\"DBSCAN eps=1,72 min_samples=2\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=np.mean(modeles_calinski_harabasz, axis=0),colLabels=column_labels,rowLabels=row_labels,loc=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5640435",
   "metadata": {},
   "source": [
    "#### Score de Davies-Bouldin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced0c8b",
   "metadata": {},
   "source": [
    "On regarde le score de Davies-Bouldin qui va de 0 à l'infini où 0 est la meilleure classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_intra_cluster(X,labels,k):\n",
    "    d=0\n",
    "    C_k=dtw_barycenter_averaging(X[np.where(labels==k)])\n",
    "    for x in np.where(labels==k)[0]:\n",
    "            d+=dtw(C_k,X[x])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Davies_Bouldin_score(X,labels):\n",
    "    K=len(np.unique(labels))\n",
    "    score=0\n",
    "    for k in np.unique(labels):\n",
    "        maxi=0\n",
    "        for k2 in np.unique(labels):\n",
    "            if k2!=k:\n",
    "                if (distance_intra_cluster(X,labels,k)+distance_intra_cluster(X,labels,k2))/dtw(dtw_barycenter_averaging(X[np.where(labels==k)]),dtw_barycenter_averaging(X[np.where(labels==k2)]))>maxi:\n",
    "                    maxi=(distance_intra_cluster(X,labels,k)+distance_intra_cluster(X,labels,k2))/dtw(dtw_barycenter_averaging(X[np.where(labels==k)]),dtw_barycenter_averaging(X[np.where(labels==k2)]))\n",
    "        score+=maxi\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeles_davies_bouldin=np.zeros((1,5,4))\n",
    "a=Davies_Bouldin_score(X,DBSCAN(eps=e,min_samples=n,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "b=Davies_Bouldin_score(X,DBSCAN(eps=e2,min_samples=n2,metric='precomputed').fit_predict(dtw_precomputed))\n",
    "c=np.array([Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed))])\n",
    "d=np.array([Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=4,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=5,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed)),Davies_Bouldin_score(X,AgglomerativeClustering(n_clusters=6,affinity='precomputed',linkage='average').fit_predict(dtw_precomputed))])\n",
    "for k in range(1):\n",
    "    modeles_davies_bouldin[k,0]=np.array([Davies_Bouldin_score(X,TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X)),Davies_Bouldin_score(X,TimeSeriesKMeans(n_clusters=4, metric=\"dtw\").fit_predict(X)),Davies_Bouldin_score(X,TimeSeriesKMeans(n_clusters=5, metric=\"dtw\").fit_predict(X)),Davies_Bouldin_score(X,TimeSeriesKMeans(n_clusters=6, metric=\"dtw\").fit_predict(X))])\n",
    "    modeles_davies_bouldin[k,1]=c\n",
    "    modeles_davies_bouldin[k,2]=d                                  \n",
    "    modeles_davies_bouldin[k,3]=np.full(4,a)\n",
    "    modeles_davies_bouldin[k,4]=np.full(4,b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "column_labels=[\"n=3\", \"n=4\", \"n=5\",\"n=6\"]\n",
    "row_labels=[\"DTW\",\"HAC Complete\",\"HAC average\",\"DBSCAN eps=1,82 min_samples=2\",\"DBSCAN eps=1,72 min_samples=2\"]\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=np.mean(modeles_davies_bouldin, axis=0),colLabels=column_labels,rowLabels=row_labels,loc=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b9ac5",
   "metadata": {},
   "source": [
    "### Indices se retrouvant tout le temps ensemble ou jamais ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa41799",
   "metadata": {},
   "source": [
    "On va regarder les indices que l'on retrouvera souvent ensemble. On va appliquer plusieurs fois le kmeans avec la DTW et le hierarchical clustering avec un linkage complete puisque ce sont ceux qui ont le meilleur résultat sur les scores précédents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toujours_ensemble(i,j,*args):\n",
    "    for k in args:\n",
    "        if k[i]!=k[j]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dans_liste_de_liste(l,i):\n",
    "    for k in l:\n",
    "        if i in k:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_toujours_ensemble(*args):\n",
    "    l=[]\n",
    "    for i in range(125):\n",
    "        li=[]\n",
    "        if not dans_liste_de_liste(l,indice_produit[i]):\n",
    "            for j in range(125):\n",
    "                if toujours_ensemble(i,j,*args):\n",
    "                    li.append(indice_produit[j])\n",
    "            if len(li)>1:\n",
    "                l.append(li)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35da30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_trois=TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "argument3=c_trois,TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),TimeSeriesKMeans(n_clusters=3, metric=\"dtw\").fit_predict(X),AgglomerativeClustering(n_clusters=3,affinity='precomputed',linkage='complete').fit_predict(dtw_precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4677188",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=indices_toujours_ensemble(*argument3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e01ba",
   "metadata": {},
   "source": [
    "On peut aussi regarder les indices que l'on ne retrouve jamais ensemble mais cela donne une matrice qui est un peu moins lisible puisque pour chaque indice on a la liste des éléments qui ne sont pas avec lui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jamais_ensemble(i,j,*args):\n",
    "    for k in args:\n",
    "        if k[i]==k[j]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_jamais_avec_k(k,*args):\n",
    "    l=[k]\n",
    "    i=np.where(indice_produit==k)[0][0]\n",
    "    for j in range(125):\n",
    "        if jamais_ensemble(i,j,*args):\n",
    "            l.append(indice_produit[j])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9341ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "liste3=[]\n",
    "for k in indice_produit:\n",
    "    liste3.append(indices_jamais_avec_k(k,*argument3))\n",
    "liste3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
